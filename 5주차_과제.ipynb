{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYGZrjlFlriszOotgCNc9z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 01. 사이킷런 소개와 특징\n",
        "\n",
        "1) 사이킷런 : 파이썬 머신러닝 라이브러리 중 가장 많이 사용되는 라이브러리\n",
        "\n",
        "2) 특징\n",
        "\n",
        "- 쉽고 가장 파이썬스러운 API\n",
        "\n",
        "- 머신러닝을 위한 매우 다양한 알고리즘, 개발을 위한 편리한 프레임워크와 API 제공\n",
        "\n",
        "- 매우 많은 환경에서 사용되는 성숙한 라이브러리\n",
        "\n",
        "- anaconda 설치 시 기본으로 사이킷런까지 설치 완료\n",
        "\n",
        "​\n",
        "\n",
        "# 02. 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기\n",
        "\n",
        "1) 분류\n",
        "\n",
        "① 지도학습. 명확한 정답이 주어진 데이터를 학습한 뒤 미지의 정답 에측\n",
        "\n",
        "② 피처 & 레이블(분류결정값) 데이터로 모델 학습 → 테스트 데이터 세트의 레이블 예측\n",
        "\n",
        "2) 사이킷런 패키지\n",
        "\n",
        "① 사이킷런 패키지내의 모듈명 : sklearn으로 시작\n",
        "\n",
        "② sklearn.datasets : 사이킷런에서 자체적으로 제공하는 데이터 세트 생성\n",
        "\n",
        "③ sklearn.tree : 트리 기반 ML 알고리즘 구현\n",
        "\n",
        "④ sklearn.model_selection : 학습데이터/검증데이터/예측데이터로 분리. 최적의 하이퍼 파라미터로 평가\n",
        "\n",
        "* 하이퍼 파라미터 : 머신러닝 알고리즘별로 최적의 학습을 위해 직접 입력하는 파라미터, 머신러닝 알고리즘의 성능 튜닝\n",
        "\n",
        "3) 붓꽃 품종 예측 머신러닝에 사용할 것들\n",
        "\n",
        "- load_iris() : 붓꽃 데이터 세트 생성\n",
        "\n",
        "- 의사 결정 트리(Decision Tree) : DecisionTreeClassfier\n",
        "\n",
        "4) 분류 프로세스 : 데이터 세트 분리 → 모델학습 → 예측 수행 → 평가"
      ],
      "metadata": {
        "id": "ecwpm7wHM2l7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#03. 사이킷런의 기반 프레임워크 익히기\n",
        "\n",
        "1) fit(), predict()\n",
        "\n",
        "① fit() : ML 모델 학습\n",
        "\n",
        "② predict() : 학습된 모델의 예측\n",
        "\n",
        "2) Estimator : Classifier + Regressor\n",
        "\n",
        "① Classifier : 분류 알고리즘 구현 클래스\n",
        "\n",
        "② Regressor : 회귀 알고리즘 구현 클래스\n",
        "\n",
        "③ Estimator 클래스는 fit(), predict() 구현\n",
        "\n",
        "3) 사이킷런의 주요 모둘\n",
        "\n",
        "① 예제 데이터\n",
        "\n",
        "- sklearn.datasets : 사이킷런에 내장되어 예제로 제공하는 데이터 세트\n",
        "\n",
        "② 피처 처리 \n",
        "\n",
        "- sklearn.preprocessing : 데이터 전처리. ex) 문자열을 숫자형 코드 값으로 인코딩, 정규화, 스케일링\n",
        "\n",
        "- sklearn.feature_selection : 알고리즘에 큰 영향 미치는 피처를 우선순위대로 셀렉션\n",
        "\n",
        "- sklearn.feature_extraction : 텍스트 데이터&이미지데이터의 벡터화된 피처 추출\n",
        "\n",
        "③ 피처 처리 & 차원 축소\n",
        "\n",
        "- sklearn.decomposition : 차원 축소와 관련된 알고리즘 지원\n",
        "\n",
        "④ 데이터 분리, 검증 & 파라미터 튜닝\n",
        "\n",
        "- sklearn.model_selection : 교차 검증 위한 학습/테스트 데이터 분리. 그리드 서치로 최적 파라미터 추출\n",
        "\n",
        "⑤ 평가\n",
        "\n",
        "- sklearn.metrics : 분류, 회귀, 클러스터링, 페어와이즈 등 성능 측정\n",
        "\n",
        "⑥ ML 알고리즘\n",
        "\n",
        "- sklearn.ensemble : 앙상블 알고리즘. ex) 랜덤포레스트, 에이다 부스트, 그래디언트 부스팅\n",
        "\n",
        "- sklearn.linear_model : 선형회귀, 릿지, 라쏘, 로지스틱 회귀 등\n",
        "\n",
        "- sklearn.naive_bayes : 나이브 베이즈 알고리즘. ex) 가우시안 NB, 다항분포 NB\n",
        "\n",
        "- sklearn.neighbors : 최근접 이웃 알고리즘. ex) KNN\n",
        "\n",
        "- sklearn.svm : 서포트 벡터 머신 알고리즘\n",
        "\n",
        "- sklearn.tree : 의사결정트리 알고리즘\n",
        "\n",
        "- sklearn.cluster : 비지도 클러스터링 알고리즘. ex) K-평균, 계층형, DBSCAN\n",
        "\n",
        "⑦ 유틸리티\n",
        "\n",
        "- sklearn.pipeline : 변환(피처 처리 등), ML 알고리즘 학습, 예측 등 함께 묶어서 실행 가능한 유틸리티 제공\n",
        "\n",
        "4) 내장된 예제 데이터 세트\n",
        "\n",
        "① 분류, 회귀 연습용 예제 데이터\n",
        "\n",
        "- 분류 용도 : datasets.load_breast_cancer(), datasets.load_digits(), datasets.load_iris()\n",
        "\n",
        "- 회귀 용도 : datasets.load_boston(), dataasets.load_diabetes()\n",
        "\n",
        "② 분류와 클러스터링을 위한 표본 데이터 생성기\n",
        "\n",
        "- datasets.make_classifications() : 분류. 노이즈 효과를 위한 데이터 무작위로 생성\n",
        "\n",
        "- datasets.make_blobs() : 클러스터링을 위한 데이터 세트 무작위 생성. 군집 지정 개수에 따라 여러가지 클러스터링 위한 데이터 세트 생성\n",
        "\n",
        "③ 데이터 세트 키\n",
        "\n",
        "- data : 피처의 데이터 세트. ndarray\n",
        "\n",
        "- target : 분류인 경우 레이블 값, 회귀인 경우 숫자 결괏값 데이터 세트. ndarray\n",
        "\n",
        "- target_names : 개별 레이블의 이름. ndarray 또는 list\n",
        "\n",
        "- feature_names : 피처의 이름. ndarray 또는 list\n",
        "\n",
        "- DESCR : 데이터 세트에 대한 설명과 각 피처의 설명. string\n",
        "\n",
        "④ 피처 데이터 값 반환"
      ],
      "metadata": {
        "id": "6_BYN17sPiqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04. Model Selection 모듈 소개\n",
        "\n",
        "1) train_test_split() : \n",
        "\n",
        "① 학습/테스트 데이터 세트 분리\n",
        "\n",
        "② 첫 번째 파라미터로 피처 데이터 세트, 두 번째 파라미터로 레이블 데이터 세트 입력\n",
        "\n",
        "③ 선택적 입력 가능한 파라미터\n",
        "\n",
        "- test_size : 전체 데이터에서 테스트 데이터 크기 설정. 디폴트는 0.25(25%)\n",
        "\n",
        "- train_size : 전체 데이터에서 학습용 데이터 크기 설정. 보통 test_size 사용하기 때문에 잘 사용하지 않는 파라미터\n",
        "\n",
        "- shuffle : 데이터 분리 전 셔플 여부 결정. 데이터 분산시켜 보다 효율적인 학습 및 테스트 데이터 세트 생성. 디폴트는 True\n",
        "\n",
        "- random_state : 호출할 때마다 동일한 데이터 세트 생성하기 위해 주어지는 난수 값. 지정하지 않을 시 수행할 때마다 다른 데이터 세트 생성\n",
        "\n",
        "④ 튜플 형태로 반환\n",
        "\n",
        "2) 교차 검증\n",
        "\n",
        "① 과적합 : 모델이 학습 데이터에만 과도하게 최적화되어 실제 예측을 다른 데이터로 수행할 경우 예측 성능이 과도하게 떨어지는 것.\n",
        "\n",
        "② 교차 검증 : 많은 학습과 검증 세트에서 알고리즘 학습과 평가를 수행한 뒤 테스트 데이터 세트에 대해 평가하는 것. 데이터 편중을 막기 위해 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가 수행. ML에 사용되는 데이터 세트를 학습, 검증, 테스트 데이터 세트로 세분화.\n",
        "\n",
        "③ K 폴드 교차 검증\n",
        "\n",
        "- 가장 보편적으로 사용\n",
        "\n",
        "- K개의 데이터 폴드 세트 생성 후 K번만큼 각 폴드 세트에 학습과 검증 평가 반복적으로 수행\n",
        "\n",
        "- 데이터 세트 K등분 → 검증 데이터 변경해가며 총 K번 학습과 검증 수행 → 예측 평가 K개의 평균을 K 폴드 평과결과로 반영\n",
        "\n",
        "- 사이킷런에서는 KFold와 StratifiedKFold 클래스 제공\n",
        "\n",
        "- KFold 객체는 split() 호출 시 학습용/검증용 데이터로 분할할 수 있는 '인덱스를 반환'함. 실제 학습/검증 데이터 추출은 반환된 인덱스를 기반으로 개발 코드에서 직접 수행. \n",
        "\n",
        "④ Stratified K 폴드\n",
        "\n",
        "- 불균형한 분포도(특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 것)를 가진 레이블 데이터 집합을 위한 k 폴드 방식\n",
        "\n",
        "- K 폴드가 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 학습 및 데이터 세트에 제대로 분배하지 못하는 경우의 문제 해결\n",
        "\n",
        "- 원본 데이터의 레이블 분포 먼저 고려한 후 이 분포와 동일하게 학습, 검증 데이터 세트 분배\n",
        "\n",
        "- 분류에서의 교차 검증은 stratified K 폴드로 분할되어야 함\n",
        "\n",
        "- 회귀에서는 지원되지 않음(회귀 결정은 연속된 숫자값이기 때문에 결정값별로 분포 정하는 의미 없음. 이산값 형태의 레이블이어야 함)\n",
        "\n",
        "⑤ cross_val_score()\n",
        "\n",
        "- 폴드 세트 설정 & for 루프에서 반복으로 학습 및 테스트 데이터의 인덱스 추출 & 반복적으로 학습과 예측 수행하고 예측 성능 반환 한꺼번에 수행\n",
        "\n",
        "- cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_pirams=None, pre_dispatch='2*n_jobs'). X, y, scorin, cv가 주요 파라미터\n",
        "\n",
        "- estimator : Classifier / Regressor. classifier 입력시 stratified K 폴드 방식으로 레이블 값의 분포에 따라 학습/테스트 세트 분할\n",
        "\n",
        "- X : 피처 데이터 세트\n",
        "\n",
        "- y : 레이블 데이터 세트\n",
        "\n",
        "- scoring : 예측 성능 평가 지표\n",
        "\n",
        "- cv : 교차 검증 폴드 수\n",
        "\n",
        "- scoring 파라미터로 지정된 성능 지표 측정값을 배열 형태로 반환\n",
        "\n",
        "3) GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에\n",
        "\n",
        "① 하이퍼 파라미터 : 머신러닝 알고리즘을 구성하는 주요 구성 요소. 하이퍼 파라미터 조정해 알고리즘의 예측 성능 개선 가능\n",
        "\n",
        "② GridSearchCV : 데이터 세트를 교차검증 위한 학습/테스트 세트로 자동 분할, 하이퍼 파라미터 그리드에 기술된 모든 파라미터를 순차적으로 적용해 최적의 파라미터 찾음. 상대적으로 수행시간 오래 걸림\n",
        "\n",
        "③ 주요 파라미터\n",
        "\n",
        "- estimator : classifier, regressor, pipeline\n",
        "\n",
        "- param_grid : key+리스트 값을 가지는 딕셔너리. estimator의 튜닝을 위해 파라미터명과 사용될 여러 파라미터 값 지정\n",
        "\n",
        "- scoring : 예측 성능 측정할 평가 방법 지정. 보통 사이킹런의 성능 평가 지표를 지정하는 문자열(ex. 정확도의 경우 accuracy)로 지정하나 별도의 성능 평가 지표 함수도 지정 가능\n",
        "\n",
        "- cv : 교차 검증을 위해 분할되는 학습/테스트 세트의 개수 지정\n",
        "\n",
        "- refit : 디폴트=True. True로 생성 시 가장 최적의 하이퍼 파라미터 탐색 후 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학슴\n",
        "\n",
        "- fit(학습데이터세트) : 수행시 학습데이터를 cv에 기술된 폴딩 세트로 분할, param_grid에 기술된 하이퍼 파라미터를 순차적으로 변경하며 학습/평가 수행, 결과를 cv_results_ 속성에 기록\n",
        "\n",
        "- `cv_results_` : gridsearchcv의 결과 세트. 딕셔너리 형태로 key 값과 리스트 형태의 value 값 가짐"
      ],
      "metadata": {
        "id": "W1AXet-KP4Aq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 05. 데이터 전처리\n",
        "\n",
        "* 사이킷런 ML 알고리즘 적용 전, 데이터에 대해 미리 처리해야 할 기본 사항\n",
        "\n",
        "- 결손값(NaN, Null)을 고정된 다른 값으로 변환\n",
        "\n",
        "- 문자열(카테고리형 피처, 텍스트형 피처 등) 값 인코딩하여 숫자 형으로 전환\n",
        "\n",
        "​\n",
        "\n",
        "1) 데이터 인코딩\n",
        "\n",
        "① 레이블 인코딩(Label encoding)\n",
        "\n",
        "- 카테고리 피처를 코드형 숫자 값으로 변환 (cf. '01', '02' 같은 경우도 문자열이므로 1, 2로 변환해야 함)\n",
        "\n",
        "- 숫자 값의 경우 크고 작음에 대한 특성이 작용하기 때문에, 선형 회귀 등의 ML 알고리즘에 레이블 인코딩 적용시 예측성능 감소\n",
        "\n",
        "- LabelEncoder 객체 생성 후 fit(), transform() 호출해 레이블 인코딩 수행\n",
        "\n",
        "- LabelEncoder.classes_ : 문자열 값이 어떤 숫자 값으로 인코딩 되었는지 확인\n",
        "\n",
        "- LabelEncoder.inverse_transform() : 인코딩된 값 다시 디코딩\n",
        "\n",
        "② 원-핫 인코딩(One-Hot encoding)\n",
        "\n",
        "- 행 형태 피처의 고유 값을 열 형태로 차원 변환 후, 고유 값에 해당하는 칼럼에만 1 표시하고 나머지 칼럼에는 0 표시\n",
        "\n",
        "- OneHotEncoder 객체 설정 후 fit(), transform() 호출하여 원-핫 인코딩 수행\n",
        "\n",
        "- 주의사항 : OneHotEncoder로 변환 전 모든 문자열 값을 숫자형 값으로 변환 / 입력 값으로 2차원 데이터 필요\n",
        "\n",
        "- 변환 절차 : 원본 데이터 → 숫자로 인코딩(레이블 인코딩) → 원-핫 인코딩\n",
        "\n",
        "- 판다스의 get_dummies() : 숫자형 값으로 변환하지 않아도 바로 원-핫 인코딩 가능\n",
        "\n",
        "2) 피처 스케일링과 정규화\n",
        "\n",
        "① 표준화 : 데이터의 피처 각각 평균=0, 분산=1인 가우시안 정규 분포를 가진 값으로 변환. \n",
        "\n",
        "② 정규화 : 서로 다른 피처의 크기를 통일하기 위해 크기 변환. 변수를 모두 동일한 크기 단위로 비교하기 위해 개별 데이터의 크기를 모두 똑같은 단위로 변경\n",
        "\n",
        "③ 피처 스케일링 \n",
        "\n",
        "- 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업. ex)표준화, 정규화\n",
        "\n",
        "- 사이킷런 전처리에서 제공하는 Normalizer 모듈은 일반적인 정규화와 차이 有. 개별 벡터를 모든 피처 벡터의 크기로 나눔\n",
        "\n",
        "- 일반적인 의미의 표준화&정규화를 피처 스케일링으로 통칭\n",
        "\n",
        "- 사이킷런에서 제공하는 대표적인 피처 스케일러 : StandardScaler, MinMaxScaler\n",
        "\n",
        "3)StandardScaler\n",
        "\n",
        "- 표준화를 쉽게 지원. 개별 피처를 평균=0, 분산=1로 변환\n",
        "\n",
        "- 서포트 벡터 머신, 선형 회귀, 로지스틱 회귀의 경우 사전에 표준화 적용 시 예측 성능 향상\n",
        "\n",
        "- StandardSclaer 객체 생성 후 fit(), transfrom()에 변환 대상 피처 데이터 세트 입력 후 호출\n",
        "\n",
        "- transform()시 스케일 변환된 데이터 세트 ndarray꼴로 반환됨\n",
        "\n",
        "4)MinMaxScaler\n",
        "\n",
        "- 데이터값을 0과 1 사이의 범위 값으로 변환(음수 有인 경우 -1과 1 사이의 범위 값으로 변환)\n",
        "\n",
        "- 데이터의 분포가 가우시안 분포가 아닌 경우 사용\n",
        "\n",
        "5) 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점\n",
        "\n",
        "① 메소드\n",
        "\n",
        "- fit() :  데이터 변환을 위한 기준 정보(ex. 데이터 세트의 최대&최소값) 설정 적용\n",
        "\n",
        "- transform() : 설정된 정보를 이용해 데이터 변환\n",
        "\n",
        "- fit_transform() : fit()과 transform() 한 번에 적용\n",
        "\n",
        "② 유의점\n",
        "\n",
        "- scaler 객체 이용해 '학습데이터 세트'로 fit(), transform() 적용 → 적용된 스케일링 기준 정보 그대로 테스트 데이터에 적용('테스트 데이터 세트'로 다시 fit() 수행하지 않음) \n",
        "\n",
        "- fit_transform() : fit()과 transform()을 순서대로 진행하기 때문에 테스트 데이터에는 절대 사용하지 x\n",
        "\n",
        "- 전체 데이터세트에 스케일링 적용 후 학습데이터&테스트데이터로 분리하는 것이 바람직\n",
        "\n"
      ],
      "metadata": {
        "id": "BMBn-X01QV_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "# LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩 수행.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "print('인코딩 변환값:', labels)\n",
        "print('인코딩 클래스:', encoder.classes_)\n",
        "print('디코딩 원본값:', encoder.inverse_transform([4,5,2,0,1,1,3,3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqGQrhJLQwys",
        "outputId": "8c4dd7e3-1bc8-4b99-c267-c01be71343f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코딩 변환값: [0 1 4 5 3 3 2 2]\n",
            "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n",
            "디코딩 원본값: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "# 숫자 값 변환 위해 LabelEncoder로 변환\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "# 2차원 데이터로 변환\n",
        "labels = labels.reshape(-1, 1)\n",
        "\n",
        "# 원-핫 인코딩 적용\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(labels)\n",
        "oh_labels = oh_encoder.transform(labels)\n",
        "print('원-핫 인코딩 데이터')\n",
        "print(oh_labels.toarray())\n",
        "print('원-핫 인코딩 데이터 차원')\n",
        "print(oh_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua0oAU3oVRto",
        "outputId": "25c39f07-73e3-4b67-8fb4-8e1d1b086486"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원-핫 인코딩 데이터\n",
            "[[1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n",
            "원-핫 인코딩 데이터 차원\n",
            "(8, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'item':['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
        "pd.get_dummies(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "4bwxvrPaV-ZY",
        "outputId": "231ed5e9-184d-4ba7-ae28-4683f86e493e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
              "0        1         0        0         0           0         0\n",
              "1        0         1        0         0           0         0\n",
              "2        0         0        0         0           1         0\n",
              "3        0         0        0         0           0         1\n",
              "4        0         0        0         1           0         0\n",
              "5        0         0        0         1           0         0\n",
              "6        0         0        1         0           0         0\n",
              "7        0         0        1         0           0         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78c9a089-17d0-4e22-b3d6-0d8ef729c1e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_TV</th>\n",
              "      <th>item_냉장고</th>\n",
              "      <th>item_믹서</th>\n",
              "      <th>item_선풍기</th>\n",
              "      <th>item_전자레인지</th>\n",
              "      <th>item_컴퓨터</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78c9a089-17d0-4e22-b3d6-0d8ef729c1e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78c9a089-17d0-4e22-b3d6-0d8ef729c1e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78c9a089-17d0-4e22-b3d6-0d8ef729c1e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# 붓꽃 데이터 세트 로딩 후 DataFrame으로 변환\n",
        "iris = load_iris()\n",
        "iris_data = iris.data\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "\n",
        "print('feature들의 평균 값')\n",
        "print(iris_df.mean())\n",
        "print('\\nfeature들의 분산 값')\n",
        "print(iris_df.var())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQrfaLB5YSb7",
        "outputId": "e87a51ea-0bba-43f5-82a8-7cc9998d4251"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature들의 평균 값\n",
            "sepal length (cm)    5.843333\n",
            "sepal width (cm)     3.057333\n",
            "petal length (cm)    3.758000\n",
            "petal width (cm)     1.199333\n",
            "dtype: float64\n",
            "\n",
            "feature들의 분산 값\n",
            "sepal length (cm)    0.685694\n",
            "sepal width (cm)     0.189979\n",
            "petal length (cm)    3.116278\n",
            "petal width (cm)     0.581006\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# StandardScaler 객체 생성\n",
        "scaler = StandardScaler()\n",
        "# StandardScaler로 데이터 세트변환. fit(), transform() 호출\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "# transform() 시 스케일 변환된 데이터 세트가 numpy ndarray로 반환돼 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names )\n",
        "print('feature 들의 평균 값')\n",
        "print(iris_df_scaled.mean())\n",
        "print('feature 들의 분산 값')\n",
        "print(iris_df_scaled.var())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nssiEkqjYugY",
        "outputId": "c537991f-58b5-43e2-a0d2-dc66873d97a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature 들의 평균 값\n",
            "sepal length (cm)   -1.690315e-15\n",
            "sepal width (cm)    -1.842970e-15\n",
            "petal length (cm)   -1.698641e-15\n",
            "petal width (cm)    -1.409243e-15\n",
            "dtype: float64\n",
            "feature 들의 분산 값\n",
            "sepal length (cm)    1.006711\n",
            "sepal width (cm)     1.006711\n",
            "petal length (cm)    1.006711\n",
            "petal width (cm)     1.006711\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# MinMaxScaler 객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "# MinMaxScaler로 데이터 세트 변환\n",
        "# fit(), transform() 호출\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "# transform() 시 스케일 변환된 데이터 세트가 numpy ndarray로 반환되어 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns = iris.feature_names)\n",
        "print('feature들의 최솟값')\n",
        "print(iris_df_scaled.min())\n",
        "print('\\nfeature들의 최댓값')\n",
        "print(iris_df_scaled.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgIv-K9pZiwL",
        "outputId": "7b9c004c-16c6-47fa-82f9-0277970eb220"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature들의 최솟값\n",
            "sepal length (cm)    0.0\n",
            "sepal width (cm)     0.0\n",
            "petal length (cm)    0.0\n",
            "petal width (cm)     0.0\n",
            "dtype: float64\n",
            "\n",
            "feature들의 최댓값\n",
            "sepal length (cm)    1.0\n",
            "sepal width (cm)     1.0\n",
            "petal length (cm)    1.0\n",
            "petal width (cm)     1.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# 학습데이터 : 0~10, 데스트데이터 : 0~5 \n",
        "# scaler 클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1, 1)로 차원 변경\n",
        "train_array = np.arange(0, 11).reshape(-1, 1)\n",
        "test_array = np.arange(0, 5).reshape(-1, 1)\n",
        "\n",
        "# MinMaxSxaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0~1값으로 변환\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# fit() : train_array의 최솟값이 0, 최댓값이 10으로 설정\n",
        "scaler.fit(train_array)\n",
        "\n",
        "# 1/10 scale로 train_array 데이터 변환. 원본 10-->1로 변환됨\n",
        "train_scaled = scaler.transform(train_array)\n",
        "\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n",
        "\n",
        "# MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정\n",
        "scaler.fit(test_array)\n",
        "test_scaled = scaler.transform(test_array)\n",
        "\n",
        "# 1/5 scale로 test_array 데이터 변환. 원본 5->1로 변환\n",
        "test_scaled = scaler.transform(test_array)\n",
        "\n",
        "# test_array의 scale 변환 출력\n",
        "print('원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u23LzM2naHp_",
        "outputId": "e0c37e94-351a-4be4-b5a4-3370890bf204"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
            "원본 test_array 데이터: [0 1 2 3 4]\n",
            "Scale된 test_array 데이터: [0.   0.25 0.5  0.75 1.  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train_array)\n",
        "train_scaled = scaler.transform(train_array)\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n",
        "\n",
        "# test_array에 Scale로 변환 시 반드시 fit 호출하지 않고 transform()만 변환\n",
        "test_scaled = scaler.transform(test_array)\n",
        "print('원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrdXqQlDbtPN",
        "outputId": "dad73af1-4f1d-45a6-ec32-44cffe236122"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
            "원본 test_array 데이터: [0 1 2 3 4]\n",
            "Scale된 test_array 데이터: [0.  0.1 0.2 0.3 0.4]\n"
          ]
        }
      ]
    }
  ]
}