{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOJuy7gSmlFXeRKfQ2x+ST2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 로지스틱 회귀"
      ],
      "metadata": {
        "id": "EbbPTmUR5PJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이진 분류(Binary Classification)\n",
        "- 둘 중 하나를 결정하는 문제\n",
        "- 직선이 아닌, **시그모이드** 함수를 이용해 분류\n",
        "  - $ H(x) = f(Wx + b)$\n",
        "\n",
        "## 시그모이드 함수(Sigmoid Function)\n",
        "- $ H(x) = sigmoid(Wx+b) = \\frac{1}{1+e^-(Wx+b)} $\n",
        "- 최적의 W, b를 찾는 것이 목표\n",
        "  - W의 절대값이 커질 수록 경사가 가팔라짐\n",
        "- 출력값 : 0~1 사이 값\n",
        "\n",
        "## 비용 함수(Cost function)\n",
        "- 선형 회귀의 경우 MSE\n",
        "- sigmoid의 경우, 경사하강법 적용 시 글로벌 미니멈이 아닌 로컬 미니멈 값과 혼동 가능성 有 → 비용 함수의 목적에 부적합\n",
        "- 따라서 시그모이드의 경우 비용함수로 로그함수 사용\n",
        "\n",
        "## 파이토치로 로지스틱 회귀 구현하기"
      ],
      "metadata": {
        "id": "7jjq1Yp9tHJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "mMfIHTKe_-Qj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzPAT2Y0__rk",
        "outputId": "be5b7e18-5b6d-4812-88a0-11ace78d97f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f643857ecd0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor 데이터 선언\n",
        "\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "metadata": {
        "id": "gLuBUL8iABCb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 크기 확인\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WN5SUH3AFI8",
        "outputId": "e4edf3df-ce5b-489c-f457-db0efe927b39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 2])\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# W, b 선언\n",
        "\n",
        "W = torch.zeros((2, 1), requires_grad=True) # 크기는 2 x 1\n",
        "b = torch.zeros(1, requires_grad=True)"
      ],
      "metadata": {
        "id": "knnYb1LPAI7L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가설식 세우기\n",
        "# pytorch : e^x 구현 위해 torch.exp(x) 사용\n",
        "\n",
        "hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))"
      ],
      "metadata": {
        "id": "Q9n4Z2A9AL21"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hypothesis) # 예측값인 H(x) 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CguC967sAR18",
        "outputId": "ab0e9777-8802-4495-81a0-541f7b0e08f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치에서 제공하는 시그모이드 함수 사용해 가설식 구현\n",
        "\n",
        "hypothesis = torch.sigmoid(x_train.matmul(W) + b)"
      ],
      "metadata": {
        "id": "GGUkGEKWAThV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값 : 위의 결과와 동일\n",
        "\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgg5mzC5AoCr",
        "outputId": "b902a942-ff65-490e-c52e-f6d89eec66f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값, 실제값 사이의 cost 구하기기\n",
        "\n",
        "losses = -(y_train * torch.log(hypothesis) + \n",
        "           (1 - y_train) * torch.log(1 - hypothesis))\n",
        "print(losses)"
      ],
      "metadata": {
        "id": "H7NKXasyArjz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3621897c-c75e-43a2-8b18-86790d743c4f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931],\n",
            "        [0.6931]], grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 오차에 대한 전체 평균\n",
        "\n",
        "cost = losses.mean()\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvrAAkA8tZ_b",
        "outputId": "b70d1ab1-9724-4fd2-bfcf-8f2252555568"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch에서 제공하는 로지스틱 회귀의 비용함수 : binary_cross_entropy\n",
        "\n",
        "F.binary_cross_entropy(hypothesis, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-VaJXWPtdvQ",
        "outputId": "8bbc202a-dc8c-4117-8909-e122af59bb94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 훈련 과정까지 추가한 전체 코드\n",
        "\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros((2, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
        "    cost = -(y_train * torch.log(hypothesis) + \n",
        "             (1 - y_train) * torch.log(1 - hypothesis)).mean()\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9htEJvftlKV",
        "outputId": "301a807d-8614-4f8c-9c7e-83bf3d967b7a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.693147\n",
            "Epoch  100/1000 Cost: 0.134722\n",
            "Epoch  200/1000 Cost: 0.080643\n",
            "Epoch  300/1000 Cost: 0.057900\n",
            "Epoch  400/1000 Cost: 0.045300\n",
            "Epoch  500/1000 Cost: 0.037261\n",
            "Epoch  600/1000 Cost: 0.031673\n",
            "Epoch  700/1000 Cost: 0.027556\n",
            "Epoch  800/1000 Cost: 0.024394\n",
            "Epoch  900/1000 Cost: 0.021888\n",
            "Epoch 1000/1000 Cost: 0.019852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터를 그대로 입력으로 사용했을 때, 제대로 예측하는지 확인\n",
        "\n",
        "hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh0yKvf0tm75",
        "outputId": "3389b87a-d9e8-43bf-afce-77827c30d302"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.7648e-04],\n",
            "        [3.1608e-02],\n",
            "        [3.8977e-02],\n",
            "        [9.5622e-01],\n",
            "        [9.9823e-01],\n",
            "        [9.9969e-01]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# threshold=0.5로 설정\n",
        "\n",
        "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft4R7S1Ctu1i",
        "outputId": "724b85c0-66ab-4495-c652-d9a770ba060c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False],\n",
            "        [False],\n",
            "        [False],\n",
            "        [ True],\n",
            "        [ True],\n",
            "        [ True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련이 된 후의 W와 b의 값을 출력\n",
        "\n",
        "print(W, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGpsraG5tzOH",
        "outputId": "9082640e-5267-4c51-8535-78aa4a76a45a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.2530],\n",
            "        [1.5179]], requires_grad=True) tensor([-14.4819], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.Module로 구현하는 로지스틱 회귀\n",
        "nn.Linear()의 결과가 nn.Sigmoid를 거치면 로지스틱 회귀의 가설식이 됨"
      ],
      "metadata": {
        "id": "7g7J9cyet1wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파이토치의 nn.Linear와 nn.Sigmoid로 로지스틱 회귀 구현하기"
      ],
      "metadata": {
        "id": "74O84kO0uHWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoU6oP0VuLF3",
        "outputId": "1f373e61-2035-41c8-9677-f2d856cbfbe6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f643857ecd0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련데이터 텐서로 선언\n",
        "\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "metadata": {
        "id": "yrn5LLuAuOpk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Sequential : nn.Moudle 층 차례로 쌓을 수 있도록 함\n",
        "\n",
        "model = nn.Sequential(\n",
        "   nn.Linear(2, 1), # input_dim = 2, output_dim = 1\n",
        "   nn.Sigmoid() # 출력은 시그모이드 함수를 거친다\n",
        ")"
      ],
      "metadata": {
        "id": "wGiLrCcTuQeT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 넣어 예측값 확인\n",
        "\n",
        "model(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD21MIDeuXBH",
        "outputId": "96e99dcd-9ccf-4ac0-d884-fde6e85d6cf2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4020],\n",
              "        [0.4147],\n",
              "        [0.6556],\n",
              "        [0.5948],\n",
              "        [0.6788],\n",
              "        [0.8061]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 경사하강법으로 훈련\n",
        "\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YODcNb3duZRF",
        "outputId": "c05df6f0-5166-4796-e592-e4bccc15b79a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.539713 Accuracy 83.33%\n",
            "Epoch   10/1000 Cost: 0.614853 Accuracy 66.67%\n",
            "Epoch   20/1000 Cost: 0.441875 Accuracy 66.67%\n",
            "Epoch   30/1000 Cost: 0.373145 Accuracy 83.33%\n",
            "Epoch   40/1000 Cost: 0.316358 Accuracy 83.33%\n",
            "Epoch   50/1000 Cost: 0.266094 Accuracy 83.33%\n",
            "Epoch   60/1000 Cost: 0.220498 Accuracy 100.00%\n",
            "Epoch   70/1000 Cost: 0.182095 Accuracy 100.00%\n",
            "Epoch   80/1000 Cost: 0.157299 Accuracy 100.00%\n",
            "Epoch   90/1000 Cost: 0.144091 Accuracy 100.00%\n",
            "Epoch  100/1000 Cost: 0.134272 Accuracy 100.00%\n",
            "Epoch  110/1000 Cost: 0.125769 Accuracy 100.00%\n",
            "Epoch  120/1000 Cost: 0.118297 Accuracy 100.00%\n",
            "Epoch  130/1000 Cost: 0.111680 Accuracy 100.00%\n",
            "Epoch  140/1000 Cost: 0.105779 Accuracy 100.00%\n",
            "Epoch  150/1000 Cost: 0.100483 Accuracy 100.00%\n",
            "Epoch  160/1000 Cost: 0.095704 Accuracy 100.00%\n",
            "Epoch  170/1000 Cost: 0.091369 Accuracy 100.00%\n",
            "Epoch  180/1000 Cost: 0.087420 Accuracy 100.00%\n",
            "Epoch  190/1000 Cost: 0.083806 Accuracy 100.00%\n",
            "Epoch  200/1000 Cost: 0.080486 Accuracy 100.00%\n",
            "Epoch  210/1000 Cost: 0.077425 Accuracy 100.00%\n",
            "Epoch  220/1000 Cost: 0.074595 Accuracy 100.00%\n",
            "Epoch  230/1000 Cost: 0.071969 Accuracy 100.00%\n",
            "Epoch  240/1000 Cost: 0.069526 Accuracy 100.00%\n",
            "Epoch  250/1000 Cost: 0.067248 Accuracy 100.00%\n",
            "Epoch  260/1000 Cost: 0.065118 Accuracy 100.00%\n",
            "Epoch  270/1000 Cost: 0.063122 Accuracy 100.00%\n",
            "Epoch  280/1000 Cost: 0.061247 Accuracy 100.00%\n",
            "Epoch  290/1000 Cost: 0.059483 Accuracy 100.00%\n",
            "Epoch  300/1000 Cost: 0.057820 Accuracy 100.00%\n",
            "Epoch  310/1000 Cost: 0.056250 Accuracy 100.00%\n",
            "Epoch  320/1000 Cost: 0.054764 Accuracy 100.00%\n",
            "Epoch  330/1000 Cost: 0.053357 Accuracy 100.00%\n",
            "Epoch  340/1000 Cost: 0.052022 Accuracy 100.00%\n",
            "Epoch  350/1000 Cost: 0.050753 Accuracy 100.00%\n",
            "Epoch  360/1000 Cost: 0.049546 Accuracy 100.00%\n",
            "Epoch  370/1000 Cost: 0.048396 Accuracy 100.00%\n",
            "Epoch  380/1000 Cost: 0.047299 Accuracy 100.00%\n",
            "Epoch  390/1000 Cost: 0.046252 Accuracy 100.00%\n",
            "Epoch  400/1000 Cost: 0.045251 Accuracy 100.00%\n",
            "Epoch  410/1000 Cost: 0.044294 Accuracy 100.00%\n",
            "Epoch  420/1000 Cost: 0.043376 Accuracy 100.00%\n",
            "Epoch  430/1000 Cost: 0.042497 Accuracy 100.00%\n",
            "Epoch  440/1000 Cost: 0.041653 Accuracy 100.00%\n",
            "Epoch  450/1000 Cost: 0.040843 Accuracy 100.00%\n",
            "Epoch  460/1000 Cost: 0.040064 Accuracy 100.00%\n",
            "Epoch  470/1000 Cost: 0.039315 Accuracy 100.00%\n",
            "Epoch  480/1000 Cost: 0.038593 Accuracy 100.00%\n",
            "Epoch  490/1000 Cost: 0.037898 Accuracy 100.00%\n",
            "Epoch  500/1000 Cost: 0.037228 Accuracy 100.00%\n",
            "Epoch  510/1000 Cost: 0.036582 Accuracy 100.00%\n",
            "Epoch  520/1000 Cost: 0.035958 Accuracy 100.00%\n",
            "Epoch  530/1000 Cost: 0.035356 Accuracy 100.00%\n",
            "Epoch  540/1000 Cost: 0.034773 Accuracy 100.00%\n",
            "Epoch  550/1000 Cost: 0.034210 Accuracy 100.00%\n",
            "Epoch  560/1000 Cost: 0.033664 Accuracy 100.00%\n",
            "Epoch  570/1000 Cost: 0.033137 Accuracy 100.00%\n",
            "Epoch  580/1000 Cost: 0.032625 Accuracy 100.00%\n",
            "Epoch  590/1000 Cost: 0.032130 Accuracy 100.00%\n",
            "Epoch  600/1000 Cost: 0.031649 Accuracy 100.00%\n",
            "Epoch  610/1000 Cost: 0.031183 Accuracy 100.00%\n",
            "Epoch  620/1000 Cost: 0.030730 Accuracy 100.00%\n",
            "Epoch  630/1000 Cost: 0.030291 Accuracy 100.00%\n",
            "Epoch  640/1000 Cost: 0.029864 Accuracy 100.00%\n",
            "Epoch  650/1000 Cost: 0.029449 Accuracy 100.00%\n",
            "Epoch  660/1000 Cost: 0.029046 Accuracy 100.00%\n",
            "Epoch  670/1000 Cost: 0.028654 Accuracy 100.00%\n",
            "Epoch  680/1000 Cost: 0.028272 Accuracy 100.00%\n",
            "Epoch  690/1000 Cost: 0.027900 Accuracy 100.00%\n",
            "Epoch  700/1000 Cost: 0.027538 Accuracy 100.00%\n",
            "Epoch  710/1000 Cost: 0.027186 Accuracy 100.00%\n",
            "Epoch  720/1000 Cost: 0.026842 Accuracy 100.00%\n",
            "Epoch  730/1000 Cost: 0.026507 Accuracy 100.00%\n",
            "Epoch  740/1000 Cost: 0.026181 Accuracy 100.00%\n",
            "Epoch  750/1000 Cost: 0.025862 Accuracy 100.00%\n",
            "Epoch  760/1000 Cost: 0.025552 Accuracy 100.00%\n",
            "Epoch  770/1000 Cost: 0.025248 Accuracy 100.00%\n",
            "Epoch  780/1000 Cost: 0.024952 Accuracy 100.00%\n",
            "Epoch  790/1000 Cost: 0.024663 Accuracy 100.00%\n",
            "Epoch  800/1000 Cost: 0.024381 Accuracy 100.00%\n",
            "Epoch  810/1000 Cost: 0.024104 Accuracy 100.00%\n",
            "Epoch  820/1000 Cost: 0.023835 Accuracy 100.00%\n",
            "Epoch  830/1000 Cost: 0.023571 Accuracy 100.00%\n",
            "Epoch  840/1000 Cost: 0.023313 Accuracy 100.00%\n",
            "Epoch  850/1000 Cost: 0.023061 Accuracy 100.00%\n",
            "Epoch  860/1000 Cost: 0.022814 Accuracy 100.00%\n",
            "Epoch  870/1000 Cost: 0.022572 Accuracy 100.00%\n",
            "Epoch  880/1000 Cost: 0.022336 Accuracy 100.00%\n",
            "Epoch  890/1000 Cost: 0.022104 Accuracy 100.00%\n",
            "Epoch  900/1000 Cost: 0.021877 Accuracy 100.00%\n",
            "Epoch  910/1000 Cost: 0.021655 Accuracy 100.00%\n",
            "Epoch  920/1000 Cost: 0.021437 Accuracy 100.00%\n",
            "Epoch  930/1000 Cost: 0.021224 Accuracy 100.00%\n",
            "Epoch  940/1000 Cost: 0.021015 Accuracy 100.00%\n",
            "Epoch  950/1000 Cost: 0.020810 Accuracy 100.00%\n",
            "Epoch  960/1000 Cost: 0.020609 Accuracy 100.00%\n",
            "Epoch  970/1000 Cost: 0.020412 Accuracy 100.00%\n",
            "Epoch  980/1000 Cost: 0.020219 Accuracy 100.00%\n",
            "Epoch  990/1000 Cost: 0.020029 Accuracy 100.00%\n",
            "Epoch 1000/1000 Cost: 0.019843 Accuracy 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 입력해 예측값 확인\n",
        "\n",
        "model(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-buEi04udTk",
        "outputId": "e24a2389-62b3-460d-e10c-d8cafb44d424"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.7616e-04],\n",
              "        [3.1595e-02],\n",
              "        [3.8959e-02],\n",
              "        [9.5624e-01],\n",
              "        [9.9823e-01],\n",
              "        [9.9969e-01]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# W, b값 확인\n",
        "\n",
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-j5j-A-uih1",
        "outputId": "c2d99928-0ace-4383-815d-ce7420f402ed"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[3.2534, 1.5181]], requires_grad=True), Parameter containing:\n",
            "tensor([-14.4839], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Module 없이 구현한 모델의 W, b와 유사"
      ],
      "metadata": {
        "id": "5yKWJYRuumLB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 클래스로 파이토치 모델 구현하기"
      ],
      "metadata": {
        "id": "duYa11fCurVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 로지스틱 회귀 클래스로 구현\n",
        "\n",
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x))"
      ],
      "metadata": {
        "id": "-nVPNaHcutob"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nn.Module 상속\n",
        "- __init__()\n",
        "  - 모델의 구조, 동적 저의하는 생성자 정의\n",
        "  - 객체가 갖는 속성값 초기화\n",
        "  - super() : nn.Module 클래스의 속성을 가진 채 초기화\n",
        "- forward()\n",
        "  - 학습데이터를 입력받아 forward 연산 진행시킴\n",
        "    - forward 연산 : 입력 x로부터 y를 얻는 것\n",
        "  - model 객체를 데이터와 함께 호출시 자동 실행"
      ],
      "metadata": {
        "id": "nJRVTNNru3vH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 로지스틱 회귀 클래스로 구현하기"
      ],
      "metadata": {
        "id": "QXplaTPPvkEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj5GbeSEvnE-",
        "outputId": "7607b436-1fdc-46a4-ecf6-ea6eda0155cc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f643857ecd0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "metadata": {
        "id": "0rf0SYIevoO2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x))\n",
        "        \n",
        "model = BinaryClassifier()"
      ],
      "metadata": {
        "id": "9fUp48tivybC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKO9RSIBv0R_",
        "outputId": "feaf2f78-810e-4332-f71e-e0a01c47ae27"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.539713 Accuracy 83.33%\n",
            "Epoch   10/1000 Cost: 0.614853 Accuracy 66.67%\n",
            "Epoch   20/1000 Cost: 0.441875 Accuracy 66.67%\n",
            "Epoch   30/1000 Cost: 0.373145 Accuracy 83.33%\n",
            "Epoch   40/1000 Cost: 0.316358 Accuracy 83.33%\n",
            "Epoch   50/1000 Cost: 0.266094 Accuracy 83.33%\n",
            "Epoch   60/1000 Cost: 0.220498 Accuracy 100.00%\n",
            "Epoch   70/1000 Cost: 0.182095 Accuracy 100.00%\n",
            "Epoch   80/1000 Cost: 0.157299 Accuracy 100.00%\n",
            "Epoch   90/1000 Cost: 0.144091 Accuracy 100.00%\n",
            "Epoch  100/1000 Cost: 0.134272 Accuracy 100.00%\n",
            "Epoch  110/1000 Cost: 0.125769 Accuracy 100.00%\n",
            "Epoch  120/1000 Cost: 0.118297 Accuracy 100.00%\n",
            "Epoch  130/1000 Cost: 0.111680 Accuracy 100.00%\n",
            "Epoch  140/1000 Cost: 0.105779 Accuracy 100.00%\n",
            "Epoch  150/1000 Cost: 0.100483 Accuracy 100.00%\n",
            "Epoch  160/1000 Cost: 0.095704 Accuracy 100.00%\n",
            "Epoch  170/1000 Cost: 0.091369 Accuracy 100.00%\n",
            "Epoch  180/1000 Cost: 0.087420 Accuracy 100.00%\n",
            "Epoch  190/1000 Cost: 0.083806 Accuracy 100.00%\n",
            "Epoch  200/1000 Cost: 0.080486 Accuracy 100.00%\n",
            "Epoch  210/1000 Cost: 0.077425 Accuracy 100.00%\n",
            "Epoch  220/1000 Cost: 0.074595 Accuracy 100.00%\n",
            "Epoch  230/1000 Cost: 0.071969 Accuracy 100.00%\n",
            "Epoch  240/1000 Cost: 0.069526 Accuracy 100.00%\n",
            "Epoch  250/1000 Cost: 0.067248 Accuracy 100.00%\n",
            "Epoch  260/1000 Cost: 0.065118 Accuracy 100.00%\n",
            "Epoch  270/1000 Cost: 0.063122 Accuracy 100.00%\n",
            "Epoch  280/1000 Cost: 0.061247 Accuracy 100.00%\n",
            "Epoch  290/1000 Cost: 0.059483 Accuracy 100.00%\n",
            "Epoch  300/1000 Cost: 0.057820 Accuracy 100.00%\n",
            "Epoch  310/1000 Cost: 0.056250 Accuracy 100.00%\n",
            "Epoch  320/1000 Cost: 0.054764 Accuracy 100.00%\n",
            "Epoch  330/1000 Cost: 0.053357 Accuracy 100.00%\n",
            "Epoch  340/1000 Cost: 0.052022 Accuracy 100.00%\n",
            "Epoch  350/1000 Cost: 0.050753 Accuracy 100.00%\n",
            "Epoch  360/1000 Cost: 0.049546 Accuracy 100.00%\n",
            "Epoch  370/1000 Cost: 0.048396 Accuracy 100.00%\n",
            "Epoch  380/1000 Cost: 0.047299 Accuracy 100.00%\n",
            "Epoch  390/1000 Cost: 0.046252 Accuracy 100.00%\n",
            "Epoch  400/1000 Cost: 0.045251 Accuracy 100.00%\n",
            "Epoch  410/1000 Cost: 0.044294 Accuracy 100.00%\n",
            "Epoch  420/1000 Cost: 0.043376 Accuracy 100.00%\n",
            "Epoch  430/1000 Cost: 0.042497 Accuracy 100.00%\n",
            "Epoch  440/1000 Cost: 0.041653 Accuracy 100.00%\n",
            "Epoch  450/1000 Cost: 0.040843 Accuracy 100.00%\n",
            "Epoch  460/1000 Cost: 0.040064 Accuracy 100.00%\n",
            "Epoch  470/1000 Cost: 0.039315 Accuracy 100.00%\n",
            "Epoch  480/1000 Cost: 0.038593 Accuracy 100.00%\n",
            "Epoch  490/1000 Cost: 0.037898 Accuracy 100.00%\n",
            "Epoch  500/1000 Cost: 0.037228 Accuracy 100.00%\n",
            "Epoch  510/1000 Cost: 0.036582 Accuracy 100.00%\n",
            "Epoch  520/1000 Cost: 0.035958 Accuracy 100.00%\n",
            "Epoch  530/1000 Cost: 0.035356 Accuracy 100.00%\n",
            "Epoch  540/1000 Cost: 0.034773 Accuracy 100.00%\n",
            "Epoch  550/1000 Cost: 0.034210 Accuracy 100.00%\n",
            "Epoch  560/1000 Cost: 0.033664 Accuracy 100.00%\n",
            "Epoch  570/1000 Cost: 0.033137 Accuracy 100.00%\n",
            "Epoch  580/1000 Cost: 0.032625 Accuracy 100.00%\n",
            "Epoch  590/1000 Cost: 0.032130 Accuracy 100.00%\n",
            "Epoch  600/1000 Cost: 0.031649 Accuracy 100.00%\n",
            "Epoch  610/1000 Cost: 0.031183 Accuracy 100.00%\n",
            "Epoch  620/1000 Cost: 0.030730 Accuracy 100.00%\n",
            "Epoch  630/1000 Cost: 0.030291 Accuracy 100.00%\n",
            "Epoch  640/1000 Cost: 0.029864 Accuracy 100.00%\n",
            "Epoch  650/1000 Cost: 0.029449 Accuracy 100.00%\n",
            "Epoch  660/1000 Cost: 0.029046 Accuracy 100.00%\n",
            "Epoch  670/1000 Cost: 0.028654 Accuracy 100.00%\n",
            "Epoch  680/1000 Cost: 0.028272 Accuracy 100.00%\n",
            "Epoch  690/1000 Cost: 0.027900 Accuracy 100.00%\n",
            "Epoch  700/1000 Cost: 0.027538 Accuracy 100.00%\n",
            "Epoch  710/1000 Cost: 0.027186 Accuracy 100.00%\n",
            "Epoch  720/1000 Cost: 0.026842 Accuracy 100.00%\n",
            "Epoch  730/1000 Cost: 0.026507 Accuracy 100.00%\n",
            "Epoch  740/1000 Cost: 0.026181 Accuracy 100.00%\n",
            "Epoch  750/1000 Cost: 0.025862 Accuracy 100.00%\n",
            "Epoch  760/1000 Cost: 0.025552 Accuracy 100.00%\n",
            "Epoch  770/1000 Cost: 0.025248 Accuracy 100.00%\n",
            "Epoch  780/1000 Cost: 0.024952 Accuracy 100.00%\n",
            "Epoch  790/1000 Cost: 0.024663 Accuracy 100.00%\n",
            "Epoch  800/1000 Cost: 0.024381 Accuracy 100.00%\n",
            "Epoch  810/1000 Cost: 0.024104 Accuracy 100.00%\n",
            "Epoch  820/1000 Cost: 0.023835 Accuracy 100.00%\n",
            "Epoch  830/1000 Cost: 0.023571 Accuracy 100.00%\n",
            "Epoch  840/1000 Cost: 0.023313 Accuracy 100.00%\n",
            "Epoch  850/1000 Cost: 0.023061 Accuracy 100.00%\n",
            "Epoch  860/1000 Cost: 0.022814 Accuracy 100.00%\n",
            "Epoch  870/1000 Cost: 0.022572 Accuracy 100.00%\n",
            "Epoch  880/1000 Cost: 0.022336 Accuracy 100.00%\n",
            "Epoch  890/1000 Cost: 0.022104 Accuracy 100.00%\n",
            "Epoch  900/1000 Cost: 0.021877 Accuracy 100.00%\n",
            "Epoch  910/1000 Cost: 0.021655 Accuracy 100.00%\n",
            "Epoch  920/1000 Cost: 0.021437 Accuracy 100.00%\n",
            "Epoch  930/1000 Cost: 0.021224 Accuracy 100.00%\n",
            "Epoch  940/1000 Cost: 0.021015 Accuracy 100.00%\n",
            "Epoch  950/1000 Cost: 0.020810 Accuracy 100.00%\n",
            "Epoch  960/1000 Cost: 0.020609 Accuracy 100.00%\n",
            "Epoch  970/1000 Cost: 0.020412 Accuracy 100.00%\n",
            "Epoch  980/1000 Cost: 0.020219 Accuracy 100.00%\n",
            "Epoch  990/1000 Cost: 0.020029 Accuracy 100.00%\n",
            "Epoch 1000/1000 Cost: 0.019843 Accuracy 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 소프트맥스 회귀"
      ],
      "metadata": {
        "id": "phx5Jbvjv2YT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B7-gK78-v8-S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}